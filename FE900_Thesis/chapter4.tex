\chapter{FPGA System Architecture and Methodology}

To validate the hypothesis that an AI-integrated FPGA can outperform traditional market-making strategies, we propose a hybrid system architecture. This architecture is founded upon a deterministic, pure FPGA tick-to-trade (T2T) pipeline by replacing its static decision logic with a hardware-accelerated reinforcement learning (RL) inference core.

This design is composed of two primary components, both specified in the underlying technical architecture:
\begin{itemize}
    \item \textbf{The Ultra-Low-Latency (ULL) Data Path:} A "pure-in-gates" FPGA pipeline responsible for all operations on the critical path, from network ingress to order egress.
    \item \textbf{The Hybrid Control Plane:} A software-based system (running on a host CPU) responsible for training the RL model and updating its parameters on the FPGA via a non-critical control path.
\end{itemize}

\section{The Ultra-Low-Latency T2T Data Path (FPGA)}

Our data path foundation is a deterministic, end-to-end T2T pipeline architecture. This design ensures our system operates with deterministic, sub-microsecond latency, eliminating OS jitter and software overheads.

\subsection{Network Ingress \& Parsing (rx\_parser)}
The system ingests 10/25GbE market data feeds directly from the PHY. The \texttt{rx\_parser} module implements a Finite State Machine (FSM) to strip headers and extract the payload.

\begin{figure}[h!]
    \centering
    \caption{State Machine for RX Parser}
    \begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=2.5cm, semithick]
      \tikzstyle{every state}=[fill=blue!10,draw=none,text=black]

      \node[state, initial] (ETH) {ST\_ETH};
      \node[state] (IP) [right of=ETH] {ST\_IP};
      \node[state] (UDP) [right of=IP] {ST\_UDP};
      \node[state] (PAY) [right of=UDP] {ST\_PAY};

      \path 
        (ETH) edge node {Cycle 0} (IP)
        (IP) edge node {Cycle 1} (UDP)
        (UDP) edge node {Cycle 2} (PAY)
        (PAY) edge [loop above] node {Payload Stream} (PAY)
              edge [bend left] node {tlast=1} (ETH);
    \end{tikzpicture}
\end{figure}

The FSM cycles through:
\begin{enumerate}
    \item \textbf{ST\_ETH:} Consumes the 14-byte Ethernet header.
    \item \textbf{ST\_IP:} Extracts Source/Dest IP from the 20-byte IPv4 header.
    \item \textbf{ST\_UDP:} Extracts Source/Dest Ports from the 8-byte UDP header and asserts \texttt{header\_valid}.
    \item \textbf{ST\_PAY:} Streams the remaining payload data to the decoder until \texttt{tlast} is asserted.
\end{enumerate}

\subsection{Feed Handling \& Book Building (itch\_decoder)}
The \texttt{itch\_decoder} module is responsible for identifying and parsing specific market data messages.

\begin{figure}[h!]
    \centering
    \caption{ITCH Decoder Logic Flow}
    \begin{tikzpicture}[node distance = 1.5cm, auto]
        \tikzstyle{block} = [rectangle, draw, fill=green!10, text width=8em, text centered, rounded corners, minimum height=3em]
        \tikzstyle{line} = [draw, -latex', thick]
        
        \node [block] (input) {Input Stream};
        \node [block, right=of input] (buffer) {Accumulation Buffer (512-bit)};
        \node [block, below=of buffer] (check) {Length Check (>288 bits)};
        \node [block, right=of check] (extract) {Field Extraction};
        \node [block, below=of extract] (output) {Normalized Tick};

        \path [line] (input) -- (buffer);
        \path [line] (buffer) -- (check);
        \path [line] (check) -- node {Yes} (extract);
        \path [line] (extract) -- (output);
    \end{tikzpicture}
\end{figure}

Logic flow:
\begin{itemize}
    \item \textbf{Accumulation:} Incoming 64-bit words are shifted into a large internal buffer (`buffer`).
    \item \textbf{Detection:} The logic checks if the buffer contains enough bits for a full "Add Order" message (Type 'A', 36 bytes).
    \item \textbf{Extraction:} Once valid, it extracts the Order ID, Price, and Quantity fields using fixed bit-offsets and generates a single-cycle \texttt{tick\_valid} pulse.
\end{itemize}

\subsection{Strategy \& Risk (The Core Integration)}

\section{Core Integration: The RL-Inference Module}

The key innovation of this thesis is the replacement of the static \texttt{strat\_decide} module (Listing 5). The baseline implementation uses a simple, threshold-based logic (e.g., \texttt{(ask\_px0 + thresh\_buy < fair\_px)}). This is precisely the static model our literature review identifies as suboptimal in volatile markets.

We will replace this module with a custom-designed \textbf{RL-Inference Core}.

\begin{itemize}
    \item \textbf{Inputs:} This new module will receive the same high-speed signals from the book builder (e.g., \texttt{bid\_px0}, \texttt{ask\_px0}) but will also be fed additional real-time state features, such as order flow imbalances, volatility metrics (calculated in hardware), and the current inventory state (held in registers).
    \item \textbf{Logic:} The core itself will be a pipelined neural network (or other RL-based model) implemented directly in Verilog/VHDL. It will be architected to meet the aggressive latency budget of the module it replaces (approx. 30â€“100 ns).
    \item \textbf{Outputs:} The module will output a \texttt{buy} or \texttt{sell} decision and the dynamically calculated \texttt{in\_px} and \texttt{in\_qty}. These outputs feed directly into the \textit{existing} \texttt{risk\_gate} module (Listing 6).
\end{itemize}

This design retains the safety of the original pipeline. The AI's decisions are still subject to deterministic, hardware-based pre-trade risk checks (e.g., \texttt{notional\_limit}, \texttt{msg\_rate\_limit}). The AI can \textit{propose} a trade, but the hard-wired risk module provides the final "pass" or "kill" signal, mitigating adverse selection from a misbehaving model.

\section{The Hybrid Control Plane for Model Management}

A key challenge in AI-FPGA integration is model training and updating. The FPGA is for \textit{inference}, not \textit{training}. We will leverage the optional PCIe/DMA control plane for this purpose. This "slower" sideband channel is critical and will be used for:

\begin{enumerate}
    \item \textbf{Model Deployment:} The CPU-based software stack will be responsible for training/retraining the RL model. After training, the optimized model weights (parameters) will be written into the FPGA's registers (e.g., BRAMs, LUTs) via the AXI-Lite register file (Listing 9). This allows for dynamic model updates without recompiling the FPGA.
    \item \textbf{Telemetry and Monitoring:} We will use this same PCIe path to export high-resolution timestamps, counters, and latency histograms, which is essential for our evaluation.
\end{enumerate}

This hybrid approach ensures the critical trading path remains purely in hardware and is \textit{never} back-pressured by the software/control plane. The implementation of this high-performance software plane is detailed in Section 5.
