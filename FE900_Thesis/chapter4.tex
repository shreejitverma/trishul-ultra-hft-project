\chapter{FPGA System Methodology and Implementation}

This chapter delineates the methodological approach taken to realize the proposed AI-integrated high-frequency trading system. The central hypothesis—that hardware-accelerated reinforcement learning can improve market-making performance—necessitates a hybrid architecture. This architecture bifurcates the system into two distinct domains: an Ultra-Low-Latency (ULL) Data Path for execution, and a Hybrid Control Plane for model management.

\section{The Ultra-Low-Latency Data Path Implementation}

The data path is architected as a "pure-in-gates" pipeline, ensuring that every operation on the critical path—from the arrival of a packet to the dispatch of an order—occurs deterministically within the FPGA fabric.

\subsection{Network Ingress: Deterministic Parsing}
The ingress pipeline minimizes latency by processing network headers in parallel with data arrival. The \texttt{rx_parser} module implements a hierarchical Finite State Machine (FSM) that decouples protocol layers.
\begin{itemize}
    \item \textbf{Cycle 0 (Ethernet):} The FSM identifies the Start of Frame (SOF) and consumes the 14-byte Ethernet header.
    \item \textbf{Cycle 1 (IPv4):} Source and Destination IP addresses are extracted. The module validates the IP checksum in real-time.
    \item \textbf{Cycle 2 (UDP):} Port numbers are verified against a programmable whitelist. This early-discard mechanism ensures that only relevant market data enters the processing pipeline.
    \item \textbf{Payload Streaming:} Once validated, the FSM asserts a valid signal, streaming the payload to the decoder. This "cut-through" design allows downstream processing to begin before the entire packet has been buffered.
\end{itemize}

\subsection{Feed Handling: Semantic Extraction}
The \texttt{itch_decoder} transforms the raw byte stream into semantic market events. It employs a 512-bit shift register to accumulate incoming words. Pattern matching logic scans this buffer for specific message type identifiers (e.g., 'A' for Add Order). Upon detection, combinatorial logic extracts the Price and Quantity fields using fixed bit-offsets, normalizing them into a standardized internal format. This removes the variability of the wire protocol from the core logic.

\section{Core Innovation: The RL-Inference Module}

The pivotal contribution of this work is the replacement of static decision logic with the \texttt{strat_decide.v} module. This hardware core embeds a trained Reinforcement Learning policy directly into the datapath. To meet the stringent timing requirements of a 300 MHz clock domain, the inference engine is structured as a 4-stage pipeline:

\begin{enumerate}
    \item \textbf{Stage 1: Feature Extraction.} The module computes derived market features in real-time. These include the Bid-Ask Spread, the Order Book Imbalance (OBI), and the Inventory Skew. These calculations utilize dedicated adders and subtractors to produce a feature vector.
    \item \textbf{Stage 2: DSP-Accelerated MAC.} The feature vector is fed into a bank of Xilinx DSP48 slices. These specialized arithmetic units perform the Multiply-Accumulate (MAC) operations required for the neural network's dense layers, computing the dot-product of input features and learned weights stored in Block RAM (BRAM).
    \item \textbf{Stage 3: Hardware Activation.} The output of the MAC stage passes through an activation function. To avoid the latency of calculating exponentials for Sigmoid or Tanh, the system implements a Rectified Linear Unit (ReLU), which is efficiently synthesized as a single multiplexer logic gate (\(\max(0, x)\)).
    \item \textbf{Stage 4: Decision Thresholding.} The activated values are compared against learned thresholds to generate discrete \texttt{BUY} or \texttt{SELL} control signals.
\end{enumerate}

This pipelined architecture achieves a total inference latency of approximately 13.3 nanoseconds, effectively rendering the AI decision-making cost negligible in the context of the total system latency.

\subsection{Safety Systems: Hardware Risk Gating}
To mitigate the operational risks associated with probabilistic AI models, the outputs of the RL core are gated by a deterministic safety module, \texttt{risk_gate}. This module enforces hard constraints on:
\begin{itemize}
    \item \textbf{Max Notional Value:} Preventing orders that exceed a predefined dollar amount.
    \item \textbf{Message Rate:} Limiting the frequency of orders to prevent runaway loops (e.g., "quote stuffing").
\end{itemize}
This "Safety Envelope" ensures that even in the event of model hallucination or input anomalies, the system remains within safe operating parameters.

\section{The Hybrid Control Plane}

A fundamental challenge in hardware-based trading is the rigidity of FPGA logic. To address this, we developed a PCIe-based Hybrid Control Plane. This sideband channel allows the software running on the host CPU to interact with the FPGA dynamically.
\begin{itemize}
    \item \textbf{Dynamic Parameter Updates:} The RL model weights are not hard-coded in the bitstream. Instead, they are stored in memory-mapped registers accessible via the AXI-Lite interface. This allows the software strategy engine to retrain the model on recent data and "hot-swap" the weights on the FPGA without interrupting the trading session.
    \item \textbf{Telemetry Export:} The FPGA exposes performance counters and high-resolution timestamps via PCIe. This observability is crucial for verifying the tick-to-trade latency and debugging the interaction between the RL model and live market data.
\end{itemize}
